{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I found a bugh while training a random model\n",
    "\n",
    "For some reason the ntilde kept growing and this lead testing 1080 ntilde with 1080 remaining idx. \n",
    "\n",
    "This is exactly half of the \" complete \" dataset, having excluded 1000 test images.\n",
    "\n",
    "Running this notebook should reproduce the bug.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0 (from utils.py)\n",
      "Using device: cuda:0 (from utils.py)\n",
      "Device is: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import threading \n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "\n",
    "import copy\n",
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "importlib.reload(utils)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)  # if you are using multi-GPU.\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "TORCH_DTYPE = torch.float64 #NB: Basically all of the matrices in Spatial_GP have 1.e-7 added to the diagonal, to be changed if we want to use float64\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "torch.set_default_dtype(TORCH_DTYPE)\n",
    "torch.set_default_device(device)\n",
    "print(f'Device is: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2753, 1430, 1101,  ...,  341,   27,  647], device='cuda:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative or zero input to log detected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 126\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Estimate the utility and cap the maximum r ( used in a summation to infinity )\u001b[39;00m\n\u001b[1;32m    125\u001b[0m r_masked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mTORCH_DTYPE)\n\u001b[0;32m--> 126\u001b[0m u2d      \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mnd_utility(logf_var, logf_mean, r_masked )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# i_best   = u2d.argmax()                 # Index of the best image in the utility vector\u001b[39;00m\n\u001b[1;32m    129\u001b[0m i_best \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, u2d\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/IDV_code/Variational_GP/Gaussian-Processes/Spatial_GP_repo/bug_check/../utils.py:516\u001b[0m, in \u001b[0;36mnd_utility\u001b[0;34m(sigma2, mu, r_masked)\u001b[0m\n\u001b[1;32m    514\u001b[0m     mu     \u001b[38;5;241m=\u001b[39m mu[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Returns the the Laplace approximation of p(r|x,D) and the masked r tensor to use in the sum in mean_noise entropy. \u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m p_response, log_p_response, r_masked_2d, log_r2d_fact_masked \u001b[38;5;241m=\u001b[39m nd_p_r_given_xD( r\u001b[38;5;241m=\u001b[39mr_masked, sigma2\u001b[38;5;241m=\u001b[39msigma2, mu\u001b[38;5;241m=\u001b[39mmu, )  \u001b[38;5;66;03m# shape (r, nstar), shape (r, nstar), shape (r, nstar)\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# Response entropy H(r|x,D) [eq 28 Paper PNAS]\u001b[39;00m\n\u001b[1;32m    519\u001b[0m H_r_xD \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum( p_response\u001b[38;5;241m*\u001b[39mlog_p_response, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m )  \u001b[38;5;66;03m# shape (1, nstar)\u001b[39;00m\n",
      "File \u001b[0;32m~/IDV_code/Variational_GP/Gaussian-Processes/Spatial_GP_repo/bug_check/../utils.py:496\u001b[0m, in \u001b[0;36mnd_p_r_given_xD\u001b[0;34m(r, sigma2, mu)\u001b[0m\n\u001b[1;32m    493\u001b[0m r          \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(sum_mask, r, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.\u001b[39m))           \u001b[38;5;66;03m# shape (r, nstar)\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m# We woulnd't need to unsqueeze / add an empty first dimension to sigma2. It's just to show that we are dividing each column of lambda_mean by the corresponding sigma2\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m log_p \u001b[38;5;241m=\u001b[39m lambda_mean\u001b[38;5;241m*\u001b[39mr \u001b[38;5;241m-\u001b[39m ex_lambda_mean \u001b[38;5;241m-\u001b[39m ((lambda_mean\u001b[38;5;241m-\u001b[39mmu)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39msigma2\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39msafe_log( ex_lambda_mean\u001b[38;5;241m*\u001b[39msigma2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m log_r_fact \u001b[38;5;66;03m# TODO: is this factorial too slow?\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mexp(log_p), log_p, r, log_r_fact\n",
      "File \u001b[0;32m~/IDV_code/Variational_GP/Gaussian-Processes/Spatial_GP_repo/bug_check/../utils.py:668\u001b[0m, in \u001b[0;36msafe_log\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_log\u001b[39m(x):\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;66;03m# Wrapper function to log that checks for negative or zero input\u001b[39;00m\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(x \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 668\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative or zero input to log detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;66;03m# print(\"Warning: Negative or zero input to log detected\")\u001b[39;00m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(x \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-10\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: Negative or zero input to log detected"
     ]
    }
   ],
   "source": [
    "cellid       = 8         # Choose cell\n",
    "ntrain_start = 50        # Number of first training data points\n",
    "\n",
    "kernfun      = 'acosker' # Choose kernel function\n",
    "\n",
    "nEstep       = 10         # Total number of E-steps iterations.\n",
    "nFparamstep  = 10  \n",
    "nMstep       = 10         # Total number of M-steps iterations. \n",
    "maxiter      = 10         # Iterations of the optimization algorithm comprising M and E steps\n",
    "\n",
    "ntilde       = ntrain_start\n",
    "n_test_lk    = 1000       # Number of test data points on which to compute log-likelihood, to compare 2 models without using the r2 score\n",
    "\n",
    "# region _______ Import dataset and fix random indices _______\n",
    "# Open the .pkl dataset file for reading in binary mode (rb)\n",
    "with open('/home/idv-eqs8-pza/IDV_code/Variational_GP/spatial_GP/Data/data2_41mixed_tr28.pkl', 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    loaded_data = pickle.load(file)\n",
    "    # loaded_data is a Dataset object from module Data with attributes \"images_train, _val, _test\" as well as responses\n",
    "\n",
    "X_train = torch.tensor(loaded_data.images_train).to(device, dtype=TORCH_DTYPE) #shape (2910,108,108,1) where 108 is the number of pixels. 2910 is the amount of training points\n",
    "X_val   = torch.tensor(loaded_data.images_val).to(device, dtype=TORCH_DTYPE)\n",
    "X_test  = torch.tensor(loaded_data.images_test).to(device, dtype=TORCH_DTYPE) # shape (30,108,108,1) # nimages, npx, npx\n",
    "\n",
    "R_train = torch.tensor(loaded_data.responses_train).to(device, dtype=TORCH_DTYPE) #shape (2910,41) 2910 is the amount of training data, 41 is the number of cells\n",
    "R_val   = torch.tensor(loaded_data.responses_val).to(device, dtype=TORCH_DTYPE)\n",
    "R_test  = torch.tensor(loaded_data.responses_test).to(device, dtype=TORCH_DTYPE) # shape (30,30,42) 30 repetitions, 30 images, 42 cells\n",
    "\n",
    "# Create the complete dataset\n",
    "X = torch.cat( (X_train, X_val), axis=0,) #shape (3160,108,108,1)\n",
    "R = torch.cat( (R_train, R_val), axis=0,)\n",
    "\n",
    "n_px_side = X.shape[1]  \n",
    "\n",
    "# Reshape images to 1D vector and choose a cell\n",
    "X = torch.reshape(X, ( X.shape[0], X.shape[1]*X.shape[2])) \n",
    "R = R[:,cellid] # shape (nt,) where nt is the number of trials\n",
    "\n",
    "# Choose a random subset of the data and save the idx\n",
    "all_idx  = torch.arange(0, X.shape[0])                     # Indices of the whole dataset  \n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "all_idx_perm  = torch.randperm(all_idx.shape[0])                         # Random permutation of the indices\n",
    "\n",
    "test_1000_idx = all_idx_perm[-n_test_lk:]                                # Take the last 1000 images out of the set\n",
    "all_idx_perm  = all_idx_perm[~torch.isin( all_idx_perm, test_1000_idx )] # Remove the test set indices from the permutation\n",
    "\n",
    "X_test_1000   = X[test_1000_idx,:]\n",
    "R_test_1000   = R[test_1000_idx]\n",
    "\n",
    "# endregion\n",
    "\n",
    "bug_model = utils.load_model(f'../models/bugs/cell:8_negative_variance')\n",
    "\n",
    "# region __________ Retrieve the values from the last model fit __________\n",
    "in_use_idx    = bug_model['fit_parameters']['in_use_idx']\n",
    "xtilde_idx    = bug_model['fit_parameters']['xtilde_idx']\n",
    "\n",
    "print(xtilde_idx)\n",
    "\n",
    "remaining_idx = all_idx_perm[~torch.isin( all_idx_perm, in_use_idx )]\n",
    "\n",
    "X_remaining = X[remaining_idx]\n",
    "R_remaining = R[remaining_idx]\n",
    "\n",
    "xtilde = X[xtilde_idx]  # This has to be the same as start_model['xtilde']\n",
    "\n",
    "xstar  = X_remaining\n",
    "\n",
    "kernfun       = bug_model['fit_parameters']['kernfun']\n",
    "if kernfun == 'acosker': kernfun = utils.acosker\n",
    "n_px_side     = bug_model['fit_parameters']['n_px_side']\n",
    "EIGVAL_TOL    = bug_model['fit_parameters']['eigval_tol']\n",
    "\n",
    "final_kernel  = bug_model['final_kernel']\n",
    "\n",
    "mask          = bug_model['mask']\n",
    "C             = bug_model['C']\n",
    "B             = bug_model['B']\n",
    "K_tilde_b     = bug_model['K_tilde_b']\n",
    "K_tilde_inv_b = bug_model['K_tilde_inv_b']\n",
    "K_b           = bug_model['K_b']\n",
    "Kvec          = bug_model['Kvec']\n",
    "m_b           = bug_model['m_b']\n",
    "V_b           = bug_model['V_b']    \n",
    "f_params      = bug_model['f_params']\n",
    "theta         = bug_model['hyperparams_tuple'][0]\n",
    "A             = torch.exp(f_params['logA'])\n",
    "lambda0       = torch.exp(f_params['loglambda0']) if 'loglambda0' in f_params else f_params['lambda0']\n",
    "\n",
    "theta_lower_lims  = bug_model['hyperparams_tuple'][1]\n",
    "theta_higher_lims = bug_model['hyperparams_tuple'][2]\n",
    "\n",
    "# endregion\n",
    "\n",
    "# region __________ Calculate the loglikelihood on the 1000 Test set __________\n",
    "\n",
    "Kvec_test = utils.acosker(theta, X_test_1000[:,mask], x2=None, C=C, dC=None, diag=True)\n",
    "K_test    = utils.acosker(theta, X_test_1000[:,mask], x2=xtilde[:,mask], C=C, dC=None, diag=False)\n",
    "K_test_b  = K_test @ B \n",
    "\n",
    "lambda_m_t, lambda_var_t = utils.lambda_moments(X_test_1000[:,mask], K_tilde_b, K_test_b@K_tilde_inv_b, Kvec_test, K_test_b, C, m_b, V_b, theta)\n",
    "\n",
    "f_mean = utils.mean_f_given_lambda_moments(f_params, lambda_m_t, lambda_var_t)\n",
    "\n",
    "loglk_test_1000_random = utils.compute_loglikelihood(R_test_1000, f_mean, lambda_m_t, lambda_var_t, f_params)[0] \n",
    "\n",
    "# endregion    \n",
    "\n",
    "# region __________ Calculate the utility of each remaining image __________\n",
    "# Calculate the matrices to compute the lambda moments. They are referred to the unseen images xstar\n",
    "\n",
    "# xstar = xstar[:1080,:]\n",
    "\n",
    "Kvec_star = utils.acosker(theta, xstar[:,mask], x2=None, C=C, dC=None, diag=True)\n",
    "K_star    = utils.acosker(theta, xstar[:,mask], x2=xtilde[:,mask], C=C, dC=None, diag=False)\n",
    "K_star_b  = K_star @ B \n",
    "\n",
    "lambda_m_t, lambda_var_t = utils.lambda_moments( xstar[:,mask], K_tilde_b, K_star_b@K_tilde_inv_b, Kvec_star, K_star_b, C, m_b, V_b, theta)  \n",
    "\n",
    "logf_mean = A*lambda_m_t + lambda0\n",
    "logf_var  = A**2 * lambda_var_t\n",
    "\n",
    "# Estimate the utility and cap the maximum r ( used in a summation to infinity )\n",
    "r_masked = torch.arange(0, 100, dtype=TORCH_DTYPE)\n",
    "u2d      = utils.nd_utility(logf_var, logf_mean, r_masked )\n",
    "\n",
    "# i_best   = u2d.argmax()                 # Index of the best image in the utility vector\n",
    "i_best = torch.randint(0, u2d.shape[0], (1,)).item()\n",
    "x_idx_best   = remaining_idx[i_best]    # Index of the best image in the dataset indices\n",
    "print(f'Utility: {u2d[i_best].item():<8.6f} |  Best image ID: {i_best}  | Best image index: {x_idx_best}')\n",
    "\n",
    "# endregion\n",
    "\n",
    "X_remaining.mean().item()\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
